{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning\n",
    "### A Basic Introduction in *Three Acts*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Index\n",
    "\n",
    "1\\. <a href=\"#/2/1\">Act 1: Motivation and Basics</a>\n",
    "   * <a href=\"#/15/1\">The perceptron</a>.\n",
    "   * <a href=\"#/15/1\">Multilayer Perceptrons</a>.\n",
    "   \n",
    "2\\. <a href=\"#/25/1\">Act 2: Convolutional Neural Networks (CNN)</a>:\n",
    "   * Pretrained models\n",
    "   * Feature extraction.\n",
    "\n",
    "3\\. <a href=\"#/25/1\">Act 3: Recurrent Neural Networks (RNNs)</a>:\n",
    "   * Long short-term memory (LSTM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Challenges  Motivating Deep Learning\n",
    "\n",
    "* ## Central problems of AI: Speech recognition and Object recognition.\n",
    "* ## The problem of representation learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Origins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/dlframeworks.png\" style=\"width: 1200px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/gluon.png\" style=\"width: 1200px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic regression\n",
    "\n",
    "<center><img src=\"./images/logistic.png\" style=\"width: 400px;\"/></center>\n",
    "\n",
    "$\\hat{y} = w[0] * x[0] + w[1] * x[1] + ... + w[p] * x[p] + b$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/mlp.png\" style=\"width: 400px;\"/></center>\n",
    "\n",
    "$h[0] = tanh(w[0, 0] * x[0] + w[1, 0] * x[1] + w[2, 0] * x[2] + w[3, 0] * x[3])$\n",
    "$h[1] = tanh(w[0, 0] * x[0] + w[1, 0] * x[1] + w[2, 0] * x[2] + w[3, 0] * x[3])$\n",
    "$h[2] = tanh(w[0, 0] * x[0] + w[1, 0] * x[1] + w[2, 0] * x[2] + w[3, 0] * x[3])$ \n",
    "$Å· = v[0] * h[0] + v[1] * h[1] + v[2] * h[2]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic concepts.\n",
    "\n",
    "* Activation function.\n",
    "* Cost Function.\n",
    "* Gradient-Based Learning.\n",
    "* Back propagation algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Activation Functions\n",
    "* ### The role of activation functions is make neural networks non-linear.\n",
    "* ### Ensure that the representation in the input space is mapped to a different space in the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/activation-functions.png\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cost Function\n",
    "## Cross-entropy\n",
    "\n",
    "* A measure of how good a ML algorithm is doing on a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/cross-entropy.gif\" style=\"width: 1000px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient-Based Learning\n",
    "##  Stochastic Gradient Descent (SGD).\n",
    "\n",
    "* Learning $\\to$ Minimizing the Cost Function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/optimizers.gif\" style=\"width: 1000px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Back-Propagation algorithm\n",
    "## Recursive Chain Rule of Calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Perceptron\n",
    "## Multiclass logistic regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/MarkI_perceptron.jpeg\" style=\"width: 600px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The MNIST dataset\n",
    "\n",
    "<center><img src=\"./images/mnist.jpg\" style=\"width: 700px;\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# lets define first if we want to use cpu or gpu.\n",
    "# Note: don't use gpu on small projects, it is a waste of resources!\n",
    "\n",
    "ctx = mx.cpu()\n",
    "# or if you're lucky enough!\n",
    "#ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def transform(data, label):\n",
    "    return data.astype(np.float32)/255, label.astype(np.float32)\n",
    "mnist_train = mx.gluon.data.vision.MNIST(train=True, transform=transform)\n",
    "mnist_test = mx.gluon.data.vision.MNIST(train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1) 5.0\n"
     ]
    }
   ],
   "source": [
    "image, label = mnist_train[0]\n",
    "print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "im = mx.nd.tile(image, (1,1,3))\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gKMIPBPUf/Iqa+Y/vp7oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2af55d668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(im.asnumpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_data = mx.gluon.data.DataLoader(mnist_train, batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mnist_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "W = nd.random_normal(shape=(num_inputs, num_outputs))\n",
    "b = nd.random_normal(shape=num_outputs)\n",
    "\n",
    "params = [W, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(y_linear):\n",
    "    exp = nd.exp(y_linear-nd.max(y_linear))\n",
    "    norms = nd.sum(exp, axis=0, exclude=True).reshape((-1,1))\n",
    "    return exp / norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.15231057  0.16100822  0.12744138  0.11056453  0.1451381   0.11903051\n",
      "   0.05478317  0.00829658  0.02635268  0.09507422]\n",
      " [ 0.03087835  0.17347507  0.02534506  0.13982475  0.26483524  0.06327081\n",
      "   0.07679356  0.12304549  0.07744105  0.02509063]]\n",
      "<NDArray 2x10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "sample_y_linear = nd.random_normal(shape=(2,10))\n",
    "sample_yhat = softmax(sample_y_linear)\n",
    "print(sample_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.99999994  1.        ]\n",
      "<NDArray 2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(nd.sum(sample_yhat, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    y_linear = nd.dot(X, W) + b\n",
    "    yhat = softmax(y_linear)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy(yhat, y):\n",
    "    return - nd.sum(y * nd.log(yhat), axis=0, exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/mnist-perceptron.png\" style=\"width: 700px;\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx).reshape((-1,784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        label_one_hot = nd.one_hot(label, 10)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        numerator += nd.sum(predictions == label)\n",
    "        denominator += data.shape[0]\n",
    "    return (numerator / denominator).asscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What should be the value of `evaluate_accuracy(test_data,net)` ?\n",
    "\n",
    "https://goo.gl/tFGNXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "https://goo.gl/kyg5HS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.098999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(test_data, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.475698532743, Train_acc 0.888133, Test_acc 0.8893\n",
      "Epoch 2. Loss: 0.46018093139, Train_acc 0.890633, Test_acc 0.8926\n",
      "Epoch 4. Loss: 0.415295991026, Train_acc 0.893067, Test_acc 0.8947\n",
      "Epoch 6. Loss: 0.414896261722, Train_acc 0.896367, Test_acc 0.8963\n",
      "Epoch 8. Loss: 0.400268483964, Train_acc 0.8986, Test_acc 0.8979\n",
      "Epoch 10. Loss: 0.39769824387, Train_acc 0.900717, Test_acc 0.9006\n"
     ]
    }
   ],
   "source": [
    "epochs = 11\n",
    "moving_loss = 0.\n",
    "learning_rate = .001\n",
    "smoothing_constant = .01\n",
    "niter=0\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx).reshape((-1,784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        label_one_hot = nd.one_hot(label, 10)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = cross_entropy(output, label_one_hot)\n",
    "        loss.backward()\n",
    "        SGD(params, learning_rate)\n",
    "\n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        niter +=1\n",
    "        moving_loss = (1 - smoothing_constant) * moving_loss + (smoothing_constant) * nd.mean(loss).asscalar()\n",
    "        est_loss = moving_loss/(1-(1-smoothing_constant)**niter)\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    if e%2==0:\n",
    "        print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" \n",
    "              % (e, est_loss, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABECAYAAACRbs5KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2a850da20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions are: \n",
      "[ 4.  5.  5.  5.  5.  7.  1.  7.  9.  0.]\n",
      "<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Define the function to do prediction\n",
    "def model_predict(net,data):\n",
    "    output = net(data)\n",
    "    return nd.argmax(output, axis=1)\n",
    "\n",
    "# let's sample 10 random data points from the test set\n",
    "sample_data = mx.gluon.data.DataLoader(mnist_test, 10, shuffle=True)\n",
    "for i, (data, label) in enumerate(sample_data):\n",
    "    data = data.as_in_context(ctx)\n",
    "    print(data.shape)\n",
    "    im = nd.transpose(data,(1,0,2,3))\n",
    "    im = nd.reshape(im,(28,10*28,1))\n",
    "    imtiles = nd.tile(im, (1,1,3))\n",
    "\n",
    "    plt.imshow(imtiles.asnumpy())\n",
    "    plt.show()\n",
    "    pred=model_predict(net,data.reshape((-1,784)))\n",
    "    print('model predictions are:', pred)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## We can get nearly 90% accuracy at this task just by training a linear model for a few seconds! You might reasonably conclude that this problem is too easy to be taken seriously by experts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multilayer perceptrons from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd\n",
    "ctx = mx.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "batch_size = 64\n",
    "def transform(data, label):\n",
    "    return data.astype(np.float32)/255, label.astype(np.float32)\n",
    "train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=True, transform=transform),\n",
    "                                      batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                     batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#  Set some constants so it's easy to modify the network later\n",
    "#######################\n",
    "num_hidden = 128\n",
    "weight_scale = .01\n",
    "\n",
    "#######################\n",
    "#  Allocate parameters for the first hidden layer\n",
    "#######################\n",
    "W1 = nd.random_normal(shape=(num_inputs, num_hidden), scale=weight_scale, ctx=ctx)\n",
    "b1 = nd.random_normal(shape=num_hidden, scale=weight_scale, ctx=ctx)\n",
    "\n",
    "#######################\n",
    "#  Allocate parameters for the second hidden layer\n",
    "#######################\n",
    "W2 = nd.random_normal(shape=(num_hidden, num_hidden), scale=weight_scale, ctx=ctx)\n",
    "b2 = nd.random_normal(shape=num_hidden, scale=weight_scale, ctx=ctx)\n",
    "\n",
    "#######################\n",
    "#  Allocate parameters for the output layer\n",
    "#######################\n",
    "W3 = nd.random_normal(shape=(num_hidden, num_outputs), scale=weight_scale, ctx=ctx)\n",
    "b3 = nd.random_normal(shape=num_outputs, scale=weight_scale, ctx=ctx)\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return nd.maximum(X, nd.zeros_like(X))\n",
    "\n",
    "def softmax(y_linear):\n",
    "    exp = nd.exp(y_linear-nd.max(y_linear))\n",
    "    partition = nd.nansum(exp, axis=0, exclude=True).reshape((-1, 1))\n",
    "    return exp / partition\n",
    "\n",
    "\n",
    "def cross_entropy(yhat, y):\n",
    "    return - nd.nansum(y * nd.log(yhat), axis=0, exclude=True)\n",
    "\n",
    "\n",
    "def softmax_cross_entropy(yhat_linear, y):\n",
    "    return - nd.nansum(y * nd.log_softmax(yhat_linear), axis=0, exclude=True)\n",
    "\n",
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    #######################\n",
    "    #  Compute the first hidden layer\n",
    "    #######################\n",
    "    h1_linear = nd.dot(X, W1) + b1\n",
    "    h1 = relu(h1_linear)\n",
    "\n",
    "    #######################\n",
    "    #  Compute the second hidden layer\n",
    "    #######################\n",
    "    h2_linear = nd.dot(h1, W2) + b2\n",
    "    h2 = relu(h2_linear)\n",
    "\n",
    "    #######################\n",
    "    #  Compute the output layer.\n",
    "    #  We will omit the softmax function here\n",
    "    #  because it will be applied\n",
    "    #  in the softmax_cross_entropy loss\n",
    "    #######################\n",
    "    yhat_linear = nd.dot(h2, W3) + b3\n",
    "    return yhat_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/mnist-mlp.png\" style=\"width: 1000px;\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        numerator += nd.sum(predictions == label)\n",
    "        denominator += data.shape[0]\n",
    "    return (numerator / denominator).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = .001\n",
    "smoothing_constant = .01\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        label_one_hot = nd.one_hot(label, 10)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label_one_hot)\n",
    "        loss.backward()\n",
    "        SGD(params, learning_rate)\n",
    "\n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    if e%2==0: \n",
    "        print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" %\n",
    "              (e, moving_loss, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## It seems everything works! Or maybe we are missing something?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# With great flexibility comes overfitting liability\n",
    "\n",
    "## Include Regularization:\n",
    "* $l1$ and $l2$\n",
    "* Dropout (Srivastava, Hinton  et al., 2012)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 10 mins break?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "* Convolution and pooling layers as part of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Origins and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/cnn.png\" style=\"width: 1200px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What it is convolution?\n",
    "* Basically, kind of matrix multiplication.\n",
    "* Depending of the method, it reduces the size of the original image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[248   4]\n",
      " [-28 236]\n",
      " [  2 -14]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal as sg\n",
    "\n",
    "A = [[255, 7, 3],\n",
    "     [212, 240, 4],\n",
    "     [218, 216, 230]]\n",
    "\n",
    "C = [[-1, 1]]\n",
    "\n",
    "print(sg.convolve(C,A, \"valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[248,   4,   3],\n",
       "       [-28, 236,   4],\n",
       "       [  2, -14, 230]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "ndimage.convolve(A, C,mode='constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is the convolution of  \n",
    "$\\begin{bmatrix}\n",
    "    1  & -1  \\\\\n",
    "   -1  & 1  \\\\\n",
    "\\end{bmatrix}$\n",
    "with\n",
    "$[1 , -1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2]\n",
      " [ 2]]\n"
     ]
    }
   ],
   "source": [
    "print(sg.convolve([[1,-1],[-1,1]],[[1,-1]], \"valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow,subplots\n",
    "from matplotlib import cm\n",
    "\n",
    "def image2pixelarray(filepath):\n",
    "    im = Image.open(filepath).convert('L')\n",
    "    (width, height) = im.size\n",
    "    greyscale_map = list(im.getdata())\n",
    "    greyscale_map = np.array(greyscale_map)\n",
    "    greyscale_map = greyscale_map.reshape((height, width))\n",
    "    return greyscale_map\n",
    "\n",
    "def norm(ar):\n",
    "    return 255.*np.absolute(ar)/np.max(ar)\n",
    "\n",
    "def convimage(path,MConv):\n",
    "    fig, ax = subplots(figsize=(10,10))\n",
    "    img2p = image2pixelarray(path)\n",
    "    imgconv = norm(sg.convolve(img2p,MConv))\n",
    "    img = Image.fromarray(imgconv).convert('L')\n",
    "    return ax.imshow(np.asarray(img),cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "path = 'images/cat.png'\n",
    "img_or = Image.open(path).convert('L')\n",
    "fig, ax = subplots(figsize=(10,10))\n",
    "ax.imshow(np.asarray(img_or),cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# horizontal edges\n",
    "M1 = [[1], [-1]]\n",
    "convimage(path,M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# vertical edges\n",
    "M2 = [[1, -1]]\n",
    "convimage(path,M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sharpen= [[0, -1, 0],\n",
    "          [-1, 5, -1],\n",
    "          [0, -1, 0]]\n",
    "convimage(path,sharpen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "laplacian = [[0, 1, 0],\n",
    "             [1, -4, 1],\n",
    "             [0, 1, 0]]\n",
    "convimage(path,laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#construct the Sobel x-axis kernel\n",
    "sobelX = [[-1, 0, 1],\n",
    "          [-2, 0, 2],\n",
    "          [-1, 0, 1]]\n",
    "convimage(path,sobelX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# construct the Sobel y-axis kernel\n",
    "sobelY = [[-1, -2, -1],\n",
    "          [0, 0, 0],\n",
    "          [1, 2, 1]]\n",
    "convimage(path,sobelY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Box blur\n",
    "Boxblur = [[0.1,0.1,0.1],\n",
    "           [0.1,0.1,0.1],\n",
    "           [0.1,0.1,0.1]]\n",
    "convimage(path,Boxblur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is pooling?\n",
    "\n",
    "* Again kind of matrix operation.\n",
    "* The final image is resized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.measure\n",
    "\n",
    "a = np.array([\n",
    "      [  20,  200,   -5,   23],\n",
    "      [ -13,  134,  119,  100],\n",
    "      [ 120,   32,   49,   25],\n",
    "      [-120,   12,    9,   23]\n",
    "])\n",
    "skimage.measure.block_reduce(a, (2,2), np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "skimage.measure.block_reduce(a, (2,2), np.average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def poolimage(path,kernel=(2,2),method=np.max):\n",
    "    fig, ax = subplots(figsize=(10,10))\n",
    "    img2p = image2pixelarray(path)\n",
    "    poolimage = norm(skimage.measure.block_reduce(img2p, kernel,method))\n",
    "    img = Image.fromarray(poolimage).convert('L')\n",
    "    return ax.imshow(np.asarray(img),cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# methods = np.average, np.max\n",
    "# kernel -> tuple\n",
    "poolimage(path,(3,3),np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional neural networks from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "import numpy as np\n",
    "ctx = mx.cpu()\n",
    "mx.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "def transform(data, label):\n",
    "    return nd.transpose(data.astype(np.float32), (2,0,1))/255, label.astype(np.float32)\n",
    "train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=True, transform=transform),\n",
    "                                      batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                     batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#  Set the scale for weight initialization and choose\n",
    "#  the number of hidden units in the fully-connected layer\n",
    "#######################\n",
    "weight_scale = .01\n",
    "num_fc = 128\n",
    "\n",
    "W1 = nd.random_normal(shape=(20, 1, 3,3), scale=weight_scale, ctx=ctx)\n",
    "b1 = nd.random_normal(shape=20, scale=weight_scale, ctx=ctx)\n",
    "\n",
    "W2 = nd.random_normal(shape=(50, 20, 5, 5), scale=weight_scale, ctx=ctx)\n",
    "b2 = nd.random_normal(shape=50, scale=weight_scale, ctx=ctx)\n",
    "\n",
    "W3 = nd.random_normal(shape=(800, num_fc), scale=weight_scale, ctx=ctx)\n",
    "b3 = nd.random_normal(shape=128, scale=weight_scale, ctx=ctx)\n",
    "\n",
    "W4 = nd.random_normal(shape=(num_fc, num_outputs), scale=weight_scale, ctx=ctx)\n",
    "b4 = nd.random_normal(shape=10, scale=weight_scale, ctx=ctx)\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3, W4, b4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "for data, _ in train_data:\n",
    "    data = data.as_in_context(ctx)\n",
    "    break\n",
    "conv = nd.Convolution(data=data, weight=W1, bias=b1, kernel=(3,3), num_filter=20)\n",
    "print(conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20, 13, 13)\n"
     ]
    }
   ],
   "source": [
    "pool = nd.Pooling(data=conv, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "print(pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return nd.maximum(X,nd.zeros_like(X))\n",
    "\n",
    "def softmax(y_linear):\n",
    "    exp = nd.exp(y_linear-nd.max(y_linear))\n",
    "    partition = nd.sum(exp, axis=0, exclude=True).reshape((-1,1))\n",
    "    return exp / partition\n",
    "\n",
    "def softmax_cross_entropy(yhat_linear, y):\n",
    "    return - nd.nansum(y * nd.log_softmax(yhat_linear), axis=0, exclude=True)\n",
    "\n",
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def net(X, debug=False):\n",
    "    ########################\n",
    "    #  Define the computation of the first convolutional layer\n",
    "    ########################\n",
    "    h1_conv = nd.Convolution(data=X, weight=W1, bias=b1, kernel=(3,3), num_filter=20)\n",
    "    h1_activation = relu(h1_conv)\n",
    "    h1 = nd.Pooling(data=h1_activation, pool_type=\"avg\", kernel=(2,2), stride=(2,2))\n",
    "    if debug:\n",
    "        print(\"h1_conv shape: %s\" % (np.array(h1_conv.shape)))\n",
    "        print(\"h1 shape: %s\" % (np.array(h1.shape)))\n",
    "\n",
    "    ########################\n",
    "    #  Define the computation of the second convolutional layer\n",
    "    ########################\n",
    "    h2_conv = nd.Convolution(data=h1, weight=W2, bias=b2, kernel=(5,5), num_filter=50)\n",
    "    h2_activation = relu(h2_conv)\n",
    "    h2 = nd.Pooling(data=h2_activation, pool_type=\"avg\", kernel=(2,2), stride=(2,2))\n",
    "    if debug:\n",
    "        print(\"h2_conv shape: %s\" % (np.array(h2_conv.shape)))\n",
    "        print(\"h2 shape: %s\" % (np.array(h2.shape)))\n",
    "\n",
    "    ########################\n",
    "    #  Flattening h2 so that we can feed it into a fully-connected layer\n",
    "    ########################\n",
    "    h2 = nd.flatten(h2)\n",
    "    if debug:\n",
    "        print(\"Flat h2 shape: %s\" % (np.array(h2.shape)))\n",
    "\n",
    "    ########################\n",
    "    #  Define the computation of the third (fully-connected) layer\n",
    "    ########################\n",
    "    h3_linear = nd.dot(h2, W3) + b3\n",
    "    h3 = relu(h3_linear)\n",
    "    if debug:\n",
    "        print(\"h3 shape: %s\" % (np.array(h3.shape)))\n",
    "\n",
    "    ########################\n",
    "    #  Define the computation of the output layer\n",
    "    ########################\n",
    "    yhat_linear = nd.dot(h3, W4) + b4\n",
    "    if debug:\n",
    "        print(\"yhat_linear shape: %s\" % (np.array(yhat_linear.shape)))\n",
    "\n",
    "    return yhat_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        label_one_hot = nd.one_hot(label, 10)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        numerator += nd.sum(predictions == label)\n",
    "        denominator += data.shape[0]\n",
    "    return (numerator / denominator).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1_conv shape: [64 20 26 26]\n",
      "h1 shape: [64 20 13 13]\n",
      "h2_conv shape: [64 50  9  9]\n",
      "h2 shape: [64 50  4  4]\n",
      "Flat h2 shape: [ 64 800]\n",
      "h3 shape: [ 64 128]\n",
      "yhat_linear shape: [64 10]\n"
     ]
    }
   ],
   "source": [
    "output = net(data, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "learning_rate = .01\n",
    "smoothing_constant = .01\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        label_one_hot = nd.one_hot(label, num_outputs)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label_one_hot)\n",
    "        loss.backward()\n",
    "        SGD(params, learning_rate)\n",
    "\n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" % (e, moving_loss, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some remarks:\n",
    "* Deep convolutional neural networks.\n",
    "* Very deep networks with repeating elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predict with pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/lenet-to-resnet.jpg\" style=\"width: 1000px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "path='http://data.mxnet.io/models/imagenet-11k/'\n",
    "[mx.test_utils.download(path+'resnet-152/resnet-152-symbol.json'),\n",
    " mx.test_utils.download(path+'resnet-152/resnet-152-0000.params'),\n",
    " mx.test_utils.download(path+'synset.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-152', 0)\n",
    "mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "         label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "with open('synset.txt', 'r') as f:\n",
    "    labels = [l.rstrip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "# define a simple data batch\n",
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "def get_image(url, show=False):\n",
    "    # download and show the image\n",
    "    fname = mx.test_utils.download(url)\n",
    "    img = cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "         return None\n",
    "    if show:\n",
    "         plt.imshow(img)\n",
    "         plt.axis('off')\n",
    "    # convert into format (batch, RGB, width, height)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)\n",
    "    img = img[np.newaxis, :]\n",
    "    return img\n",
    "\n",
    "def predict(url):\n",
    "    img = get_image(url, show=True)\n",
    "    # compute the predict probabilities\n",
    "    mod.forward(Batch([mx.nd.array(img)]))\n",
    "    prob = mod.get_outputs()[0].asnumpy()\n",
    "    # print the top-5\n",
    "    prob = np.squeeze(prob)\n",
    "    a = np.argsort(prob)[::-1]\n",
    "    for i in a[0:5]:\n",
    "        print('probability=%f, class=%s' %(prob[i], labels[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predict('http://writm.com/wp-content/uploads/2016/08/Cat-hd-wallpapers.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predict('http://thenotoriouspug.com/wp-content/uploads/2015/01/Pug-Cookie-1920x1080-1024x576.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extra: Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# list the last 10 layers\n",
    "all_layers = sym.get_internals()\n",
    "all_layers.list_outputs()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fe_sym = all_layers['flatten0_output']\n",
    "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
    "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "fe_mod.set_params(arg_params, aux_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "img = get_image('http://writm.com/wp-content/uploads/2016/08/Cat-hd-wallpapers.jpg')\n",
    "fe_mod.forward(Batch([mx.nd.array(img)]))\n",
    "features = fe_mod.get_outputs()[0].asnumpy()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The ConvNet ZOO\n",
    "* LeNet (1990).\n",
    "* AlexNet (ILSVRC 2012).\n",
    "* ZF Net (ILSVRC 2013).\n",
    "* GoogLeNet (ILSVRC 2014).\n",
    "* VGGNet (2014).\n",
    "* ResNet. Residual Network (ILSVRC 2015).\n",
    "\n",
    "ILSVRC: ImageNet Large Scale Visual Recognition Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "<a href=\"#/1/1\">(Index)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent Neural Networks (RNNs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "import numpy as np\n",
    "mx.random.seed(1)\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/timemachine.txt\") as f:\n",
    "    time_machine = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(time_machine[-38075:-37500])\n",
    "time_machine = time_machine[:-38083]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "character_list = list(set(time_machine))\n",
    "vocab_size = len(character_list)\n",
    "print(character_list)\n",
    "print(\"Length of vocab: %s\" % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "character_dict = {}\n",
    "for e, char in enumerate(character_list):\n",
    "    character_dict[char] = e\n",
    "print(character_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_numerical = [character_dict[char] for char in time_machine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#  Check that the length is right\n",
    "#########################\n",
    "print(len(time_numerical))\n",
    "\n",
    "#########################\n",
    "#  Check that the format looks right\n",
    "#########################\n",
    "print(time_numerical[:20])\n",
    "\n",
    "#########################\n",
    "#  Convert back to text\n",
    "#########################\n",
    "print(\"\".join([character_list[idx] for idx in time_numerical[:39]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hots(numerical_list, vocab_size=vocab_size):\n",
    "    result = nd.zeros((len(numerical_list), vocab_size), ctx=ctx)\n",
    "    for i, idx in enumerate(numerical_list):\n",
    "        result[i, idx] = 1.0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(one_hots(time_numerical[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textify(embedding):\n",
    "    result = \"\"\n",
    "    indices = nd.argmax(embedding, axis=1).asnumpy()\n",
    "    for idx in indices:\n",
    "        result += character_list[int(idx)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textify(one_hots(time_numerical[0:40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 64\n",
    "# -1 here so we have enough characters for labels later\n",
    "num_samples = (len(time_numerical) - 1) // seq_length\n",
    "dataset = one_hots(time_numerical[:seq_length*num_samples]).reshape((num_samples, seq_length, vocab_size))\n",
    "textify(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('# of sequences in dataset: ', len(dataset))\n",
    "num_batches = len(dataset) // batch_size\n",
    "print('# of batches: ', num_batches)\n",
    "train_data = dataset[:num_batches*batch_size].reshape((num_batches, batch_size, seq_length, vocab_size))\n",
    "# swap batch_size and seq_length axis to make later access easier\n",
    "train_data = nd.swapaxes(train_data, 1, 2)\n",
    "print('Shape of data set: ', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(\"***Batch %s:***\\n %s \\n\\n\" % (i, textify(train_data[i, :, 0]) + textify(train_data[i, :, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = one_hots(time_numerical[1:seq_length*num_samples+1])\n",
    "train_label = labels.reshape((num_batches, batch_size, seq_length, vocab_size))\n",
    "train_label = nd.swapaxes(train_label, 1, 2)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(textify(train_data[0, :, 0]))\n",
    "print(textify(train_label[0, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs = 77\n",
    "num_hidden = 256\n",
    "num_outputs = 77\n",
    "\n",
    "########################\n",
    "#  Weights connecting the inputs to the hidden layer\n",
    "########################\n",
    "Wxh = nd.random_normal(shape=(num_inputs,num_hidden), ctx=ctx) * .01\n",
    "\n",
    "########################\n",
    "#  Recurrent weights connecting the hidden layer across time steps\n",
    "########################\n",
    "Whh = nd.random_normal(shape=(num_hidden,num_hidden), ctx=ctx)* .01\n",
    "\n",
    "########################\n",
    "#  Bias vector for hidden layer\n",
    "########################\n",
    "bh = nd.random_normal(shape=num_hidden, ctx=ctx) * .01\n",
    "\n",
    "\n",
    "########################\n",
    "# Weights to the output nodes\n",
    "########################\n",
    "Why = nd.random_normal(shape=(num_hidden,num_outputs), ctx=ctx) * .01\n",
    "by = nd.random_normal(shape=num_outputs, ctx=ctx) * .01\n",
    "\n",
    "# NOTE: to keep notation consistent,\n",
    "# we should really use capital letters\n",
    "# for hidden layers and outputs,\n",
    "# since we are doing batchwise computations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = [Wxh, Whh, bh, Why, by]\n",
    "\n",
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(y_linear, temperature=1.0):\n",
    "    lin = (y_linear-nd.max(y_linear)) / temperature\n",
    "    exp = nd.exp(lin)\n",
    "    partition =nd.sum(exp, axis=0, exclude=True).reshape((-1,1))\n",
    "    return exp / partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# With a temperature of 1 (always 1 during training), we get back some set of probabilities\n",
    "####################\n",
    "softmax(nd.array([[1, -1], [-1, 1]]), temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# If we set a high temperature, we can get more entropic (*noisier*) probabilities\n",
    "####################\n",
    "softmax(nd.array([[1,-1],[-1,1]]), temperature=1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "####################\n",
    "# Often we want to sample with low temperatures to produce sharp probabilities\n",
    "####################\n",
    "softmax(nd.array([[10,-10],[-10,10]]), temperature=.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_rnn(inputs, state, temperature=1.0):\n",
    "    outputs = []\n",
    "    h = state\n",
    "    for X in inputs:\n",
    "        h_linear = nd.dot(X, Wxh) + nd.dot(h, Whh) + bh\n",
    "        h = nd.tanh(h_linear)\n",
    "        yhat_linear = nd.dot(h, Why) + by\n",
    "        yhat = softmax(yhat_linear, temperature=temperature)\n",
    "        outputs.append(yhat)\n",
    "    return (outputs, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def cross_entropy(yhat, y):\n",
    "#     return - nd.sum(y * nd.log(yhat))\n",
    "\n",
    "def cross_entropy(yhat, y):\n",
    "    return - nd.mean(nd.sum(y * nd.log(yhat), axis=0, exclude=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy(nd.array([.2,.5,.3]), nd.array([1.,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_ce_loss(outputs, labels):\n",
    "    assert(len(outputs) == len(labels))\n",
    "    total_loss = 0.\n",
    "    for (output, label) in zip(outputs,labels):\n",
    "        total_loss = total_loss + cross_entropy(output, label)\n",
    "    return total_loss / len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(prefix, num_chars, temperature=1.0):\n",
    "    #####################################\n",
    "    # Initialize the string that we'll return to the supplied prefix\n",
    "    #####################################\n",
    "    string = prefix\n",
    "\n",
    "    #####################################\n",
    "    # Prepare the prefix as a sequence of one-hots for ingestion by RNN\n",
    "    #####################################\n",
    "    prefix_numerical = [character_dict[char] for char in prefix]\n",
    "    input = one_hots(prefix_numerical)\n",
    "\n",
    "    #####################################\n",
    "    # Set the initial state of the hidden representation ($h_0$) to the zero vector\n",
    "    #####################################\n",
    "    sample_state = nd.zeros(shape=(1, num_hidden), ctx=ctx)\n",
    "\n",
    "    #####################################\n",
    "    # For num_chars iterations,\n",
    "    #     1) feed in the current input\n",
    "    #     2) sample next character from from output distribution\n",
    "    #     3) add sampled character to the decoded string\n",
    "    #     4) prepare the sampled character as a one_hot (to be the next input)\n",
    "    #####################################\n",
    "    for i in range(num_chars):\n",
    "        outputs, sample_state = simple_rnn(input, sample_state, temperature=temperature)\n",
    "        choice = np.random.choice(77, p=outputs[-1][0].asnumpy())\n",
    "        string += character_list[choice]\n",
    "        input = one_hots([choice])\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "moving_loss = 0.\n",
    "\n",
    "learning_rate = .5\n",
    "\n",
    "# state = nd.zeros(shape=(batch_size, num_hidden), ctx=ctx)\n",
    "for e in range(epochs):\n",
    "    ############################\n",
    "    # Attenuate the learning rate by a factor of 2 every 100 epochs.\n",
    "    ############################\n",
    "    if ((e+1) % 100 == 0):\n",
    "        learning_rate = learning_rate / 2.0\n",
    "    state = nd.zeros(shape=(batch_size, num_hidden), ctx=ctx)\n",
    "    for i in range(num_batches):\n",
    "        data_one_hot = train_data[i]\n",
    "        label_one_hot = train_label[i]\n",
    "        with autograd.record():\n",
    "            outputs, state = simple_rnn(data_one_hot, state)\n",
    "            loss = average_ce_loss(outputs, label_one_hot)\n",
    "            loss.backward()\n",
    "        SGD(params, learning_rate)\n",
    "\n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        if (i == 0) and (e == 0):\n",
    "            moving_loss = np.mean(loss.asnumpy()[0])\n",
    "        else:\n",
    "            moving_loss = .99 * moving_loss + .01 * np.mean(loss.asnumpy()[0])\n",
    "\n",
    "    print(\"Epoch %s. Loss: %s\" % (e, moving_loss))\n",
    "    print(sample(\"The Time Ma\", 1024, temperature=.1))\n",
    "    print(sample(\"The Medical Man rose, came to the lamp,\", 1024, temperature=.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusions\n",
    "* Sentiment analysis.\n",
    "* Image captioning.\n",
    "* Text and Music generation.\n",
    "* Time series\n",
    "\n",
    "<a href=\"#/1/1\">(Index)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
